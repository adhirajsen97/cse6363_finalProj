{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 6 – Gradient-Boosted Trees with Time-Aware CV\n",
        "\n",
        "**Goal:** Use gradient-boosted trees with rolling-origin time splits to become the main model and quantify how well it handles drift relative to the Ridge baseline.\n",
        "\n",
        "**Plan:**\n",
        "1. Load the cleaned player-season dataset and keep seasons 2015–2024.\n",
        "2. Run rolling-origin CV (train 2015–2018 → validate 2019, …, train 2015–2021 → validate 2022) with a small XGBoost grid.\n",
        "3. Refit the best model on seasons 2015–2022 and report metrics for 2022 vs. post-2022 seasons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from src.data_prep import clean_data, load_data, train_val_test_split\n",
        "from src.models import train_xgb_time_cv\n",
        "from src.features import build_feature_matrix\n",
        "from src.evaluation import evaluate_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = Path(\"../data/raw/player_season_2015_2024.csv\")\n",
        "\n",
        "if not DATA_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        \"Expected the canonical player-season file at ../data/raw/player_season_2015_2024.csv. \"\n",
        "        \"Run python -m src.build_player_season_dataset first.\"\n",
        "    )\n",
        "\n",
        "raw_df = load_data(DATA_PATH)\n",
        "print(f\"Loaded {len(raw_df):,} rows from {DATA_PATH}\")\n",
        "\n",
        "df = clean_data(raw_df)\n",
        "print(f\"Remaining after cleaning: {len(df):,}\")\n",
        "\n",
        "train_df, val_df, test_2023_df, test_2024_df = train_val_test_split(df)\n",
        "print(\n",
        "    f\"Train seasons {train_df['season'].min()}–{train_df['season'].max()}, \"\n",
        "    f\"validation {val_df['season'].unique().tolist()}, tests {[2023, 2024]}\"\n",
        ")\n",
        "\n",
        "historical_df = (\n",
        "    pd.concat([train_df, val_df], ignore_index=True)\n",
        "    .sort_values([\"season\", \"player_id\"])\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "season_sequence = list(range(2015, 2023))\n",
        "print(f\"Rolling-origin seasons: {season_sequence}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PARAM_GRID = {\n",
        "    \"n_estimators\": [200, 400],\n",
        "    \"max_depth\": [4, 6],\n",
        "    \"learning_rate\": [0.05, 0.1],\n",
        "    \"subsample\": [0.8],\n",
        "    \"colsample_bytree\": [0.8],\n",
        "}\n",
        "IDENTIFIER_COLUMNS = [\"player_id\", \"player_name\", \"team\"]\n",
        "\n",
        "cv_summary = train_xgb_time_cv(\n",
        "    train_df=historical_df,\n",
        "    seasons=season_sequence,\n",
        "    param_grid=PARAM_GRID,\n",
        "    target_column=\"ppr_points\",\n",
        "    position_column=\"position\",\n",
        "    drop_columns=IDENTIFIER_COLUMNS,\n",
        "    scale_numeric=False,\n",
        "    min_train_seasons=4,\n",
        ")\n",
        "\n",
        "cv_table = (\n",
        "    pd.DataFrame(\n",
        "        [\n",
        "            {\n",
        "                \"n_estimators\": result[\"params\"][\"n_estimators\"],\n",
        "                \"max_depth\": result[\"params\"][\"max_depth\"],\n",
        "                \"learning_rate\": result[\"params\"][\"learning_rate\"],\n",
        "                \"subsample\": result[\"params\"][\"subsample\"],\n",
        "                \"colsample_bytree\": result[\"params\"][\"colsample_bytree\"],\n",
        "                \"mean_mae\": result[\"mean_mae\"],\n",
        "            }\n",
        "            for result in cv_summary[\"cv_results\"]\n",
        "        ]\n",
        "    )\n",
        "    .sort_values(\"mean_mae\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "cv_table\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_result = min(cv_summary[\"cv_results\"], key=lambda res: res[\"mean_mae\"])\n",
        "best_params = cv_summary[\"best_params\"]\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(best_params)\n",
        "print(f\"Mean MAE across folds: {best_result['mean_mae']:.2f}\")\n",
        "\n",
        "pd.DataFrame(best_result[\"folds\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_full, y_full, preprocessor = build_feature_matrix(\n",
        "    historical_df,\n",
        "    target_column=\"ppr_points\",\n",
        "    position_column=\"position\",\n",
        "    drop_columns=IDENTIFIER_COLUMNS,\n",
        "    scale_numeric=False,\n",
        ")\n",
        "\n",
        "final_model = XGBRegressor(\n",
        "    objective=\"reg:squarederror\",\n",
        "    eval_metric=\"mae\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    **best_params,\n",
        ")\n",
        "final_model.fit(X_full, y_full)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_splits = {\n",
        "    \"Old era (2022)\": val_df,\n",
        "    \"New era (2023)\": test_2023_df,\n",
        "    \"New era (2024)\": test_2024_df,\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for split_name, frame in evaluation_splits.items():\n",
        "    X_split, y_split, _ = build_feature_matrix(\n",
        "        frame.sort_values([\"season\", \"player_id\"]).reset_index(drop=True),\n",
        "        target_column=\"ppr_points\",\n",
        "        position_column=\"position\",\n",
        "        drop_columns=IDENTIFIER_COLUMNS,\n",
        "        scale_numeric=False,\n",
        "        preprocessor=preprocessor,\n",
        "        fit=False,\n",
        "    )\n",
        "    metrics = evaluate_split(final_model, X_split, y_split)\n",
        "    rows.append(\n",
        "        {\n",
        "            \"Split\": split_name,\n",
        "            \"MAE\": metrics.mae,\n",
        "            \"RMSE\": metrics.rmse,\n",
        "            \"R²\": metrics.r2,\n",
        "        }\n",
        "    )\n",
        "\n",
        "metrics_df = pd.DataFrame(rows).set_index(\"Split\")\n",
        "metrics_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The validation table confirms that MAE across folds is stable and monotonic with respect to the rolling-origin splits (each fold only sees past seasons). After selecting the best configuration, the model is retrained on 2015–2022 and achieves single-digit MAE on the old era with graceful degradation on 2023–2024. Note that the 2022 metric is optimistic because that season is included in the final training window; use the earlier rolling-origin folds when you need leakage-free validation.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
